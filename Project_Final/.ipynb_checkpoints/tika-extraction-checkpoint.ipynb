{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# take in line & month_set \n",
    "# return country name\n",
    "#\n",
    "def getCountryName(line_with_country_name):\n",
    "    months = set(['January', 'February', 'March', 'April', 'May', 'June', 'July',\\\n",
    "          'August', 'September', 'October', 'November', 'December']) \n",
    "    country = \"\"\n",
    "    for word in line_with_country_name.split():\n",
    "        if word in months:\n",
    "            break\n",
    "        country += word + \" \"\n",
    "    return country.replace(' ', '_')[:-1]\n",
    "\n",
    "\n",
    "# take in metric_list, file_name\n",
    "# return stop_index & dictionary (having data for large_territory)\n",
    "#\n",
    "def processBigTerritory(metric_list, file_name):\n",
    "    searchfile = open(file_name, \"r\",encoding='utf-8')\n",
    "    line_list = searchfile.readlines()  # read all lines into a list\n",
    "    \n",
    "    big_territory_data = {}\n",
    "    \n",
    "    for index, line in enumerate(line_list):  # enumerate the list and loop through it\n",
    "        # to grab country name\n",
    "        if \"COVID-19 Community Mobility Report\" in line:\n",
    "            line_with_country_name = str(line_list[index+2])\n",
    "            country = getCountryName(line_with_country_name)\n",
    "            big_territory_data['Territory'] = country\n",
    "        \n",
    "\n",
    "        # stop at first Residential\n",
    "        if metric_list[-1] in line:\n",
    "            big_territory_data[metric_list[-1]] = str(line_list[index+2]).split(\" \")[0][:-1]\n",
    "            stop_index = index + 1\n",
    "            break\n",
    "        \n",
    "        for metric in metric_list:\n",
    "            if metric in line:\n",
    "                big_territory_data[metric] = str(line_list[index+2]).split(\" \")[0][:-1]\n",
    "                \n",
    "    searchfile.close()\n",
    "    return big_territory_data, stop_index\n",
    "\n",
    "\n",
    "# take in stop_index (and metric_list, file_name)\n",
    "# return list[dictionaries], each dictionary contains data for a small_territory\n",
    "#\n",
    "def processSmallTerritory(stop_index, metric_list, file_name):\n",
    "    searchfile = open(file_name, \"r\",encoding='utf-8')\n",
    "    line_list = searchfile.readlines()  # read all lines into a list\n",
    "    test_data = line_list[stop_index:]\n",
    "    \n",
    "    small_territory_data_list = []\n",
    "    small_territory_data = {}\n",
    "    for line_num, new_line in enumerate(test_data): \n",
    "        for metric in metric_list:\n",
    "            if metric in new_line:\n",
    "                # to grab county name\n",
    "                if metric == \"Retail & recreation\": \n",
    "                    small_territory_data[\"Territory\"] = str(test_data[line_num-2][:-1]).replace(' ', '_') \n",
    "                    small_territory_data[\"Retail & recreation\"]= str(test_data[line_num+2]).split(\" \")[0]\n",
    "\n",
    "                if metric == 'Residential':\n",
    "                    small_territory_data['Residential'] = str(test_data[line_num+2]).split(\" \")[0]\n",
    "                    small_territory_data_list.append(small_territory_data)\n",
    "                    small_territory_data = {}\n",
    "                \n",
    "                elif metric != 'Retail & recreation' and metric != 'Residential':\n",
    "                    value = str(test_data[line_num+2])\n",
    "                    if value == 'Not enough data for this date\\n':\n",
    "                        small_territory_data[metric] = value[:-1]\n",
    "                    else: \n",
    "                        small_territory_data[metric] = value.split(\" \")[0]\n",
    "    \n",
    "    searchfile.close()\n",
    "    return list(small_territory_data_list)\n",
    "\n",
    "\n",
    "# take in path_to_file\n",
    "# output csv files, no \"return\" \n",
    "#\n",
    "def scrapePDFtoCSV(path_to_file):\n",
    "    # ------------------------- Prepocess to temp_file ------------------------        \n",
    "    # Parse data from file\n",
    "    file_data = parser.from_file(path_to_file)\n",
    "    # Get files text content\n",
    "    text = file_data['content']\n",
    "    \n",
    "    # instead of passing a huge string to support functions, better write into a temp_file and pass the filename \n",
    "    with open('temp_text.txt','wt', encoding='utf-8') as text_file:\n",
    "        text_file.write(file_data['content'])\n",
    "        text_file.close()\n",
    "\n",
    "    metric_list = ['Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplace', 'Residential']\n",
    "    file_data = [] # list of dictionaries to write to csv\n",
    "\n",
    "\n",
    "    # ------------------ Process big territory -------------------\n",
    "    big_territory_data, stop_index = processBigTerritory(metric_list, 'temp_text.txt')\n",
    "\n",
    "    # ---------------- Process smaller territories -----------------\n",
    "    small_territory_list = processSmallTerritory(stop_index, metric_list, 'temp_text.txt')\n",
    "\n",
    "    # ------------------ Merge 2 territory data into file_data list ----------------\n",
    "    small_territory_list.insert(0, big_territory_data)\n",
    "    file_data = small_territory_list\n",
    "\n",
    "    # ------------------------ Prepare to write -----------------------------\n",
    "    date_published = path_to_file.split('\\\\')[1].split('_')[0] + \"_\"\n",
    "    big_territory_name = str(big_territory_data['Territory'])\n",
    "    storage_path = os.path.join(\"./csv\", date_published + big_territory_name + \".csv\")\n",
    "                                        \n",
    "    if path_to_file.find('_US_') != -1:\n",
    "        storage_path = os.path.join(\"./csv\", \"US\", date_published + big_territory_name + \".csv\")\n",
    "    \n",
    "    # ------------------------ Write to CSV -----------------------------\n",
    "    myFile = open(storage_path, 'w', newline='', encoding='utf-8')\n",
    "    with myFile:    \n",
    "        columns = ['Territory','Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplace', 'Residential']\n",
    "        # columns = ['Territory'].append(metrics_list)\n",
    "\n",
    "        writer = csv.DictWriter(myFile, fieldnames=columns, dialect='excel')    \n",
    "        writer.writeheader()\n",
    "        for entity in file_data:\n",
    "            writer.writerow(entity)\n",
    "\n",
    "def main():\n",
    "    for filename in os.listdir('./pdfs'):\n",
    "        scrapePDFtoCSV(os.path.join('./pdfs',filename))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
