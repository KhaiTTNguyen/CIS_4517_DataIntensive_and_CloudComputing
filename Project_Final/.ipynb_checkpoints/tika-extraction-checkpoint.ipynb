{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getCountryName(line_with_country_name, months):\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "\n",
    "file = './pdfs/2020-04-11_AE_Mobility_Report_en.pdf'\n",
    "# Parse data from file\n",
    "file_data = parser.from_file(file)\n",
    "# Get files text content\n",
    "text = file_data['content']\n",
    "\n",
    "with open('text_1.txt','wt', encoding='utf-8') as text_file:\n",
    "    text_file.write(file_data['content'])\n",
    "    text_file.close()\n",
    "\n",
    "# process \n",
    "\n",
    "searchfile = open(\"text_1.txt\", \"r\",encoding='utf-8')\n",
    "line_list = searchfile.readlines()  # read all lines into a list\n",
    "\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\\\n",
    "          'August', 'September', 'October', 'November', 'December'] \n",
    "    \n",
    "metric_list = ['Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplace', 'Residential']\n",
    "for index, line in enumerate(line_list):  # enumerate the list and loop through it\n",
    "    # to grab country name\n",
    "    if \"COVID-19 Community Mobility Report\" in line:\n",
    "        line_with_country_name = str(line_list[index+2])\n",
    "        country = getCountryName(line_with_country_name, months)\n",
    "        \n",
    "    # to grab county name\n",
    "    if \"Retail & recreation\" in line: \n",
    "        print(str(line_list[index-2]))  # print three lines preceeding it\n",
    "        print(line)\n",
    "        print(str(line_list[index+2]).split(\" \")[0])\n",
    "    \n",
    "    # to grab data for other metrics \n",
    "#     for metrics in metric_list[\"grocer\":]:\n",
    "#         if metrics in line:\n",
    "#             pass # process something\n",
    "        \n",
    "searchfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' File format\n",
    "\n",
    "-CITE-\n",
    "    1 USC Sec. 2                                                01/15/2013\n",
    "\n",
    "-EXPCITE-\n",
    "    TITLE 1 - GENERAL PROVISIONS\n",
    "    CHAPTER 1 - RULES OF CONSTRUCTION\n",
    "\n",
    "-HEAD-\n",
    "    Sec. 2. \"County\" as including \"parish\", and so forth\n",
    "\n",
    "-STATUTE-\n",
    "      The word \"county\" includes a parish, or any other equivalent\n",
    "    subdivision of a State or Territory of the United States.\n",
    "\n",
    "-SOURCE-\n",
    "    (July 30, 1947, ch. 388, 61 Stat. 633.)\n",
    "\n",
    "-End-\n",
    "\n",
    "\n",
    "\n",
    "-CITE-\n",
    "    1 USC Sec. 3                                                01/15/2013\n",
    "\n",
    "-EXPCITE-\n",
    "    TITLE 1 - GENERAL PROVISIONS\n",
    "    CHAPTER 1 - RULES OF CONSTRUCTION\n",
    "\n",
    "-HEAD-\n",
    "    Sec. 3. \"Vessel\" as including all means of water transportation\n",
    "\n",
    "-STATUTE-\n",
    "      The word \"vessel\" includes every description of watercraft or\n",
    "    other artificial contrivance used, or capable of being used, as a\n",
    "    means of transportation on water.\n",
    "\n",
    "-SOURCE-\n",
    "    (July 30, 1947, ch. 388, 61 Stat. 633.)\n",
    "\n",
    "-End-\n",
    "'''\n",
    "import csv, re\n",
    "from pyparsing import Empty, FollowedBy, Group, LineEnd, Literal, OneOrMore, Optional, Regex, SkipTo, Word\n",
    "from pyparsing import alphanums, alphas, nums\n",
    "\n",
    "# def section(header, other):\n",
    "#     return Literal('-'+header+'-').suppress() + other\n",
    "\n",
    "# # return string\n",
    "# def tc(header, next_item):\n",
    "#     # <header> <number> - <name>\n",
    "#     begin = Literal(header).suppress()\n",
    "#     number = Word(nums).setResultsName('number').setParseAction(compress_whitespace)\n",
    "#     dash = Literal('-').suppress()\n",
    "#     name = SkipTo(Literal(next_item)).setResultsName('name').setParseAction(compress_whitespace)\n",
    "#     return begin + number + dash + name\n",
    "\n",
    "# def compress_whitespace(s, loc, toks):\n",
    "#     return [re.sub(r'\\s+', ' ', tok).strip() for tok in toks]\n",
    "\n",
    "def parse(data):\n",
    "    # should match anything that looks like a header\n",
    "    header = Regex(re.compile(r'-[A-Z0-9]+-')) # Regex(pattern, flags=0, asGroupList=False, asMatch=False)\n",
    "\n",
    "    # -CITE- (ignore)                         # skipping over all undefined text until the matched expression is found.\n",
    "    citation = SkipTo('-EXPCITE-').suppress() # Suppresses the output of this ParserElement; useful to keep punctuation from cluttering up returned output.\n",
    "    cite_section = section('CITE', citation)  # section(header, other)\n",
    "\n",
    "    # -EXPCITE- (parse)\n",
    "    # grab title number, title name, chapter number, chapter name\n",
    "    title = Group(tc('TITLE', 'CHAPTER')).setResultsName('title')\n",
    "    chapter = Group(tc('CHAPTER', '-HEAD-')).setResultsName('chapter')\n",
    "    expcite_section = section('EXPCITE', title + chapter)\n",
    "\n",
    "    # -HEAD- (parse)\n",
    "    # two possible forms of section number:\n",
    "    # > Sec. 1. <head_text>\n",
    "    # > CHAPTER 1 - <head_text>\n",
    "    sec_number1 = Literal(\"Sec.\").suppress() \\\n",
    "                  + Regex(r'\\d+\\w?.').setResultsName('section').setParseAction(lambda s, loc, toks: toks[0][:-1])\n",
    "    \n",
    "    sec_number2 = Literal(\"CHAPTER\").suppress() + Word(nums).setResultsName('section') + Literal(\"-\")\n",
    "    \n",
    "    sec_number = sec_number1 | sec_number2\n",
    "    head_text = SkipTo(header).setResultsName('head')\\\n",
    "                .setParseAction(compress_whitespace)\n",
    "    \n",
    "    head = sec_number + head_text\n",
    "    head_section = section('HEAD', head)\n",
    "\n",
    "    # -STATUTE- (parse)\n",
    "    statute = SkipTo(header)\\\n",
    "              .setResultsName('statute')\\\n",
    "              .setParseAction(compress_whitespace)\n",
    "    statute_section = section('STATUTE', statute)\n",
    "\n",
    "    # -End- (ignore)\n",
    "    end_section = SkipTo('-End-', include=True)\n",
    "\n",
    "    # do parsing\n",
    "    parser = OneOrMore(Group(cite_section \\\n",
    "                             + expcite_section \\\n",
    "                             + head_section \\\n",
    "                             + Optional(statute_section) \\\n",
    "                             + end_section))\n",
    "    result = parser.parseString(data)\n",
    "\n",
    "    return result\n",
    "\n",
    "def write_to_csv(parsed_data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        for item in parsed_data:\n",
    "            row = [item['title']['number'],\n",
    "                   item['title']['name'],\n",
    "                   item['chapter']['number'],\n",
    "                   item['chapter']['name'],\n",
    "                   item['section'],\n",
    "                   item['head'],\n",
    "                   item['statute']]\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "# your data is assumed to be in <source.txt>\n",
    "with open('source.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "result = parse(data)\n",
    "write_to_csv(result, 'output.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import *\n",
    "# define grammar of a greeting\n",
    "parse_string = \"Hello, World!\"\n",
    "parse_model = Word(alphas) + \",\" + Word(alphas) + \"!\"\n",
    "\n",
    "print(parse_model.parseString(parse_string)) # a nested list, a dictionary, or an object with named attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Literal('blah').parseString('blahword helooblah blah is my name blah'))  # -> ['blah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
