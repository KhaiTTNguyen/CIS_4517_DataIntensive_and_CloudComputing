{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "months = set(['January', 'February', 'March', 'April', 'May', 'June', 'July',\\\n",
    "          'August', 'September', 'October', 'November', 'December']) \n",
    "\n",
    "# take in line & month_set --> return country name\n",
    "def getCountryName(line_with_country_name, months):\n",
    "    country = \"\"\n",
    "    for word in line_with_country_name.split():\n",
    "        if word in months:\n",
    "            break\n",
    "        country += word + \" \"\n",
    "    return country.replace(' ', '_')[:-1]\n",
    "\n",
    "con = getCountryName(\"Arab Em April line\",months )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Territory': 'Czechia', 'Retail & recreation': '-67%', 'Grocery & pharmacy': '+4%', 'Parks': '+9%', 'Transit stations': '-37%', 'Workplace': '-27%', 'Residential': '+7%'}\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "# take in\n",
    "# return line_num_to_continue & dictionary\n",
    "    \n",
    "metric_list = ['Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplace', 'Residential']\n",
    "\n",
    "def processBigTerritory(metric_list, file_name):\n",
    "    searchfile = open(file_name, \"r\",encoding='utf-8')\n",
    "    line_list = searchfile.readlines()  # read all lines into a list\n",
    "    \n",
    "    big_territory_data = {}\n",
    "    \n",
    "    for index, line in enumerate(line_list):  # enumerate the list and loop through it\n",
    "        # to grab country name\n",
    "        if \"COVID-19 Community Mobility Report\" in line:\n",
    "            line_with_country_name = str(line_list[index+2])\n",
    "            country = getCountryName(line_with_country_name, months)\n",
    "            big_territory_data['Territory'] = country\n",
    "        \n",
    "\n",
    "        # stop at first Residential\n",
    "        if metric_list[-1] in line:\n",
    "            big_territory_data[metric_list[-1]] = str(line_list[index+2]).split(\" \")[0][:-1]\n",
    "            stop_index = index + 1\n",
    "            break\n",
    "        \n",
    "        for metric in metric_list:\n",
    "            if metric in line:\n",
    "                big_territory_data[metric] = str(line_list[index+2]).split(\" \")[0][:-1]\n",
    "                \n",
    "    searchfile.close()\n",
    "    return big_territory_data, stop_index\n",
    "\n",
    "b_t, i = processBigTerritory(metric_list, \"text_1.txt\")\n",
    "\n",
    "print(b_t)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Territory': 'Central_Bohemian_Region',\n",
       "  'Retail & recreation': '-56%',\n",
       "  'Grocery & pharmacy': '+8%',\n",
       "  'Parks': '+103%',\n",
       "  'Transit stations': '+6%',\n",
       "  'Workplace': '-27%',\n",
       "  'Residential': '+8%'},\n",
       " {'Territory': 'Hradec_Králové_Region',\n",
       "  'Retail & recreation': '-65%',\n",
       "  'Grocery & pharmacy': '+1%',\n",
       "  'Parks': '+22%',\n",
       "  'Transit stations': '-38%',\n",
       "  'Workplace': '-26%',\n",
       "  'Residential': '+7%'},\n",
       " {'Territory': 'Karlovy_Vary_Region',\n",
       "  'Retail & recreation': '-73%',\n",
       "  'Grocery & pharmacy': '-2%',\n",
       "  'Parks': '-11%',\n",
       "  'Transit stations': '-43%',\n",
       "  'Workplace': '-29%',\n",
       "  'Residential': '+5%'},\n",
       " {'Territory': 'Liberec_Region',\n",
       "  'Retail & recreation': '-64%',\n",
       "  'Grocery & pharmacy': '+5%',\n",
       "  'Parks': '+40%',\n",
       "  'Transit stations': '-33%',\n",
       "  'Workplace': '-28%',\n",
       "  'Residential': '+7%'},\n",
       " {'Territory': 'Moravian-Silesian_Region',\n",
       "  'Retail & recreation': '-64%',\n",
       "  'Grocery & pharmacy': '+13%',\n",
       "  'Parks': '+43%',\n",
       "  'Transit stations': '-39%',\n",
       "  'Workplace': '-24%',\n",
       "  'Residential': '+7%'},\n",
       " {'Territory': 'Olomouc_Region',\n",
       "  'Retail & recreation': '-68%',\n",
       "  'Grocery & pharmacy': '+12%',\n",
       "  'Parks': '+44%',\n",
       "  'Transit stations': '-48%',\n",
       "  'Workplace': '-26%',\n",
       "  'Residential': '+7%'},\n",
       " {'Territory': 'Pardubice_Region',\n",
       "  'Retail & recreation': '-70%',\n",
       "  'Grocery & pharmacy': '+4%',\n",
       "  'Parks': '+51%',\n",
       "  'Transit stations': '-55%',\n",
       "  'Workplace': '-23%',\n",
       "  'Residential': '+7%'},\n",
       " {'Territory': 'Plzeň_Region',\n",
       "  'Retail & recreation': '-69%',\n",
       "  'Grocery & pharmacy': '+2%',\n",
       "  'Parks': '+49%',\n",
       "  'Transit stations': '-28%',\n",
       "  'Workplace': '-29%',\n",
       "  'Residential': '+6%'},\n",
       " {'Territory': 'Prague',\n",
       "  'Retail & recreation': '-73%',\n",
       "  'Grocery & pharmacy': '-13%',\n",
       "  'Parks': '-66%',\n",
       "  'Transit stations': '-54%',\n",
       "  'Workplace': '-31%',\n",
       "  'Residential': '+7%'},\n",
       " {'Territory': 'South_Bohemian_Region',\n",
       "  'Retail & recreation': '-69%',\n",
       "  'Grocery & pharmacy': '+3%',\n",
       "  'Parks': '+43%',\n",
       "  'Transit stations': '-32%',\n",
       "  'Workplace': '-23%',\n",
       "  'Residential': '+6%'},\n",
       " {'Territory': 'South_Moravian_Region',\n",
       "  'Retail & recreation': '-66%',\n",
       "  'Grocery & pharmacy': '+4%',\n",
       "  'Parks': '+41%',\n",
       "  'Transit stations': '-31%',\n",
       "  'Workplace': '-28%',\n",
       "  'Residential': '+7%'},\n",
       " {'Territory': 'Vysocina_Region',\n",
       "  'Retail & recreation': '-67%',\n",
       "  'Grocery & pharmacy': '+12%',\n",
       "  'Parks': '+94%',\n",
       "  'Transit stations': '-23%',\n",
       "  'Workplace': '-23%',\n",
       "  'Residential': '+7%'},\n",
       " {'Territory': 'Zlin_Region',\n",
       "  'Retail & recreation': '-67%',\n",
       "  'Grocery & pharmacy': '+8%',\n",
       "  'Parks': '+44%',\n",
       "  'Transit stations': '-38%',\n",
       "  'Workplace': '-31%',\n",
       "  'Residential': '+8%'},\n",
       " {'Territory': 'Ústí_nad_Labem_Region',\n",
       "  'Retail & recreation': '-68%',\n",
       "  'Grocery & pharmacy': '+13%',\n",
       "  'Parks': '+66%',\n",
       "  'Transit stations': '-21%',\n",
       "  'Workplace': '-22%',\n",
       "  'Residential': '+5%'}]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take in line_num_to_continue\n",
    "# return list[dictionaries]\n",
    "def processSmallTerritory(stop_index, metric_list, file_name):\n",
    "    searchfile = open(file_name, \"r\",encoding='utf-8')\n",
    "    line_list = searchfile.readlines()  # read all lines into a list\n",
    "    test_data = line_list[stop_index:]\n",
    "    \n",
    "    small_territory_data_list = []\n",
    "    small_territory_data = {}\n",
    "    for line_num, new_line in enumerate(test_data): \n",
    "        for metric in metric_list:\n",
    "            if metric in new_line:\n",
    "                # to grab county name\n",
    "                if metric == \"Retail & recreation\": \n",
    "                    small_territory_data[\"Territory\"] = str(test_data[line_num-2][:-1]).replace(' ', '_') \n",
    "                    small_territory_data[\"Retail & recreation\"]= str(test_data[line_num+2]).split(\" \")[0]\n",
    "\n",
    "                if metric == 'Residential':\n",
    "                    small_territory_data['Residential'] = str(test_data[line_num+2]).split(\" \")[0]\n",
    "                    small_territory_data_list.append(small_territory_data)\n",
    "                    small_territory_data = {}\n",
    "                \n",
    "                elif metric != 'Retail & recreation' and metric != 'Residential':\n",
    "                    value = str(test_data[line_num+2])\n",
    "                    if value == 'Not enough data for this date\\n':\n",
    "                        small_territory_data[metric] = value[:-1]\n",
    "                    else: \n",
    "                        small_territory_data[metric] = value.split(\" \")[0]\n",
    "    \n",
    "    searchfile.close()\n",
    "    return list(small_territory_data_list)\n",
    "\n",
    "processSmallTerritory(140, metric_list, \"text_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def scrapPDFtoCSV(path_to_file):\n",
    "            \n",
    "    # Parse data from file\n",
    "    file_data = parser.from_file(path_to_file)\n",
    "    # Get files text content\n",
    "    text = file_data['content']\n",
    "\n",
    "    with open('text_1.txt','wt', encoding='utf-8') as text_file:\n",
    "        text_file.write(file_data['content'])\n",
    "        text_file.close()\n",
    "\n",
    "    metric_list = ['Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplace', 'Residential']\n",
    "    file_data = [] # list of dictionaries to write to csv\n",
    "\n",
    "\n",
    "    # process big territory\n",
    "    big_territory_data, stop_index = processBigTerritory(metric_list, 'text_1.txt')\n",
    "\n",
    "    # process smaller territories\n",
    "    small_territory_list = processSmallTerritory(stop_index, metric_list, 'text_1.txt')\n",
    "\n",
    "    # merge into file_data list\n",
    "    small_territory_list.insert(0, big_territory_data)\n",
    "    file_data = small_territory_list\n",
    "\n",
    "    \n",
    "    big_territory_name = str(big_territory_data['Territory'])\n",
    "    storage_path = os.path.join(\"./csv\", big_territory_name + \".csv\")\n",
    "    \n",
    "    if path_to_file.find('_US_') != -1:\n",
    "        storage_path = os.path.join(\"./csv\", \"US\", big_territory_name + \".csv\")\n",
    "        \n",
    "    myFile = open(storage_path, 'w', newline='', encoding='utf-8')\n",
    "    with myFile:    \n",
    "        columns = ['Territory','Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplace', 'Residential']\n",
    "        # columns = ['Territory'].append(metrics_list)\n",
    "\n",
    "        writer = csv.DictWriter(myFile, fieldnames=columns, dialect='excel')    \n",
    "        writer.writeheader()\n",
    "        for entity in file_data:\n",
    "            writer.writerow(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./pdfs\\2020-04-11_US_Alabama_Mobility_Report_en.pdf\n",
      "./csv\\US\\Alabama.csv\n",
      "./pdfs\\2020-04-11_US_Alaska_Mobility_Report_en.pdf\n",
      "./csv\\US\\Alaska.csv\n",
      "./pdfs\\2020-04-11_US_Arizona_Mobility_Report_en.pdf\n",
      "./csv\\US\\Arizona.csv\n",
      "./pdfs\\2020-04-11_US_Arkansas_Mobility_Report_en.pdf\n",
      "./csv\\US\\Arkansas.csv\n",
      "./pdfs\\2020-04-11_US_California_Mobility_Report_en.pdf\n",
      "./csv\\US\\California.csv\n",
      "./pdfs\\2020-04-11_US_Colorado_Mobility_Report_en.pdf\n",
      "./csv\\US\\Colorado.csv\n",
      "./pdfs\\2020-04-11_US_Connecticut_Mobility_Report_en.pdf\n",
      "./csv\\US\\Connecticut.csv\n",
      "./pdfs\\2020-04-11_US_Delaware_Mobility_Report_en.pdf\n",
      "./csv\\US\\Delaware.csv\n",
      "./pdfs\\2020-04-11_US_District_of_Columbia_Mobility_Report_en.pdf\n",
      "./csv\\US\\District_of_Columbia.csv\n",
      "./pdfs\\2020-04-11_US_Florida_Mobility_Report_en.pdf\n",
      "./csv\\US\\Florida.csv\n",
      "./pdfs\\2020-04-11_US_Georgia_Mobility_Report_en.pdf\n",
      "./csv\\US\\Georgia.csv\n",
      "./pdfs\\2020-04-11_US_Hawaii_Mobility_Report_en.pdf\n",
      "./csv\\US\\Hawaii.csv\n",
      "./pdfs\\2020-04-11_US_Idaho_Mobility_Report_en.pdf\n",
      "./csv\\US\\Idaho.csv\n",
      "./pdfs\\2020-04-11_US_Illinois_Mobility_Report_en.pdf\n",
      "./csv\\US\\Illinois.csv\n",
      "./pdfs\\2020-04-11_US_Indiana_Mobility_Report_en.pdf\n",
      "./csv\\US\\Indiana.csv\n",
      "./pdfs\\2020-04-11_US_Iowa_Mobility_Report_en.pdf\n",
      "./csv\\US\\Iowa.csv\n",
      "./pdfs\\2020-04-11_US_Kansas_Mobility_Report_en.pdf\n",
      "./csv\\US\\Kansas.csv\n",
      "./pdfs\\2020-04-11_US_Kentucky_Mobility_Report_en.pdf\n",
      "./csv\\US\\Kentucky.csv\n",
      "./pdfs\\2020-04-11_US_Louisiana_Mobility_Report_en.pdf\n",
      "./csv\\US\\Louisiana.csv\n",
      "./pdfs\\2020-04-11_US_Maine_Mobility_Report_en.pdf\n",
      "./csv\\US\\Maine.csv\n",
      "./pdfs\\2020-04-11_US_Maryland_Mobility_Report_en.pdf\n",
      "./csv\\US\\Maryland.csv\n",
      "./pdfs\\2020-04-11_US_Massachusetts_Mobility_Report_en.pdf\n",
      "./csv\\US\\Massachusetts.csv\n",
      "./pdfs\\2020-04-11_US_Michigan_Mobility_Report_en.pdf\n",
      "./csv\\US\\Michigan.csv\n",
      "./pdfs\\2020-04-11_US_Minnesota_Mobility_Report_en.pdf\n",
      "./csv\\US\\Minnesota.csv\n",
      "./pdfs\\2020-04-11_US_Mississippi_Mobility_Report_en.pdf\n",
      "./csv\\US\\Mississippi.csv\n",
      "./pdfs\\2020-04-11_US_Missouri_Mobility_Report_en.pdf\n",
      "./csv\\US\\Missouri.csv\n",
      "./pdfs\\2020-04-11_US_Mobility_Report_en.pdf\n",
      "./csv\\US\\United_States.csv\n",
      "./pdfs\\2020-04-11_US_Montana_Mobility_Report_en.pdf\n",
      "./csv\\US\\Montana.csv\n",
      "./pdfs\\2020-04-11_US_Nebraska_Mobility_Report_en.pdf\n",
      "./csv\\US\\Nebraska.csv\n",
      "./pdfs\\2020-04-11_US_Nevada_Mobility_Report_en.pdf\n",
      "./csv\\US\\Nevada.csv\n",
      "./pdfs\\2020-04-11_US_New_Hampshire_Mobility_Report_en.pdf\n",
      "./csv\\US\\New_Hampshire.csv\n",
      "./pdfs\\2020-04-11_US_New_Jersey_Mobility_Report_en.pdf\n",
      "./csv\\US\\New_Jersey.csv\n",
      "./pdfs\\2020-04-11_US_New_Mexico_Mobility_Report_en.pdf\n",
      "./csv\\US\\New_Mexico.csv\n",
      "./pdfs\\2020-04-11_US_New_York_Mobility_Report_en.pdf\n",
      "./csv\\US\\New_York.csv\n",
      "./pdfs\\2020-04-11_US_North_Carolina_Mobility_Report_en.pdf\n",
      "./csv\\US\\North_Carolina.csv\n",
      "./pdfs\\2020-04-11_US_North_Dakota_Mobility_Report_en.pdf\n",
      "./csv\\US\\North_Dakota.csv\n",
      "./pdfs\\2020-04-11_US_Ohio_Mobility_Report_en.pdf\n",
      "./csv\\US\\Ohio.csv\n",
      "./pdfs\\2020-04-11_US_Oklahoma_Mobility_Report_en.pdf\n",
      "./csv\\US\\Oklahoma.csv\n",
      "./pdfs\\2020-04-11_US_Oregon_Mobility_Report_en.pdf\n",
      "./csv\\US\\Oregon.csv\n",
      "./pdfs\\2020-04-11_US_Pennsylvania_Mobility_Report_en.pdf\n",
      "./csv\\US\\Pennsylvania.csv\n",
      "./pdfs\\2020-04-11_US_Rhode_Island_Mobility_Report_en.pdf\n",
      "./csv\\US\\Rhode_Island.csv\n",
      "./pdfs\\2020-04-11_US_South_Carolina_Mobility_Report_en.pdf\n",
      "./csv\\US\\South_Carolina.csv\n",
      "./pdfs\\2020-04-11_US_South_Dakota_Mobility_Report_en.pdf\n",
      "./csv\\US\\South_Dakota.csv\n",
      "./pdfs\\2020-04-11_US_Tennessee_Mobility_Report_en.pdf\n",
      "./csv\\US\\Tennessee.csv\n",
      "./pdfs\\2020-04-11_US_Texas_Mobility_Report_en.pdf\n",
      "./csv\\US\\Texas.csv\n",
      "./pdfs\\2020-04-11_US_Utah_Mobility_Report_en.pdf\n",
      "./csv\\US\\Utah.csv\n",
      "./pdfs\\2020-04-11_US_Vermont_Mobility_Report_en.pdf\n",
      "./csv\\US\\Vermont.csv\n",
      "./pdfs\\2020-04-11_US_Virginia_Mobility_Report_en.pdf\n",
      "./csv\\US\\Virginia.csv\n",
      "./pdfs\\2020-04-11_US_Washington_Mobility_Report_en.pdf\n",
      "./csv\\US\\Washington.csv\n",
      "./pdfs\\2020-04-11_US_West_Virginia_Mobility_Report_en.pdf\n",
      "./csv\\US\\West_Virginia.csv\n",
      "./pdfs\\2020-04-11_US_Wisconsin_Mobility_Report_en.pdf\n",
      "./csv\\US\\Wisconsin.csv\n",
      "./pdfs\\2020-04-11_US_Wyoming_Mobility_Report_en.pdf\n",
      "./csv\\US\\Wyoming.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('./pdfs'):\n",
    "    scrapPDFtoCSV(os.path.join('./pdfs',filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# each list is a row\n",
    "\n",
    "myData = [[1, 2, 3], ['Good Morning', 'Good Evening', 'Good Afternoon']]\n",
    "myFile = open('csvexample3.csv', 'w')\n",
    "with myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerows(myData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "myFile = open('countries.csv', 'w')\n",
    "with myFile:    \n",
    "    columns = ['Territory','Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplace', 'Residential']\n",
    "    \n",
    "    myFields = ['country', 'capital']\n",
    "    writer = csv.DictWriter(myFile, fieldnames=myFields)    \n",
    "    writer.writeheader()\n",
    "    data = [{'country' : 'France', 'capital': 'Paris'},{'country' : 'Italy', 'capital': 'Rome'}, {'country' : 'Spain', 'capital': 'Madrid'}, {'country' : 'Russia', 'capital': 'Moscow'}]\n",
    "    for entity in data:\n",
    "        writer.writerow(entity)\n",
    "\n",
    "#     writer.writerow({'country' : 'Italy', 'capital': 'Rome'})\n",
    "#     writer.writerow({'country' : 'Spain', 'capital': 'Madrid'})\n",
    "#     writer.writerow({'country' : 'Russia', 'capital': 'Moscow'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' File format\n",
    "\n",
    "-CITE-\n",
    "    1 USC Sec. 2                                                01/15/2013\n",
    "\n",
    "-EXPCITE-\n",
    "    TITLE 1 - GENERAL PROVISIONS\n",
    "    CHAPTER 1 - RULES OF CONSTRUCTION\n",
    "\n",
    "-HEAD-\n",
    "    Sec. 2. \"County\" as including \"parish\", and so forth\n",
    "\n",
    "-STATUTE-\n",
    "      The word \"county\" includes a parish, or any other equivalent\n",
    "    subdivision of a State or Territory of the United States.\n",
    "\n",
    "-SOURCE-\n",
    "    (July 30, 1947, ch. 388, 61 Stat. 633.)\n",
    "\n",
    "-End-\n",
    "\n",
    "\n",
    "\n",
    "-CITE-\n",
    "    1 USC Sec. 3                                                01/15/2013\n",
    "\n",
    "-EXPCITE-\n",
    "    TITLE 1 - GENERAL PROVISIONS\n",
    "    CHAPTER 1 - RULES OF CONSTRUCTION\n",
    "\n",
    "-HEAD-\n",
    "    Sec. 3. \"Vessel\" as including all means of water transportation\n",
    "\n",
    "-STATUTE-\n",
    "      The word \"vessel\" includes every description of watercraft or\n",
    "    other artificial contrivance used, or capable of being used, as a\n",
    "    means of transportation on water.\n",
    "\n",
    "-SOURCE-\n",
    "    (July 30, 1947, ch. 388, 61 Stat. 633.)\n",
    "\n",
    "-End-\n",
    "'''\n",
    "import csv, re\n",
    "from pyparsing import Empty, FollowedBy, Group, LineEnd, Literal, OneOrMore, Optional, Regex, SkipTo, Word\n",
    "from pyparsing import alphanums, alphas, nums\n",
    "\n",
    "# def section(header, other):\n",
    "#     return Literal('-'+header+'-').suppress() + other\n",
    "\n",
    "# # return string\n",
    "# def tc(header, next_item):\n",
    "#     # <header> <number> - <name>\n",
    "#     begin = Literal(header).suppress()\n",
    "#     number = Word(nums).setResultsName('number').setParseAction(compress_whitespace)\n",
    "#     dash = Literal('-').suppress()\n",
    "#     name = SkipTo(Literal(next_item)).setResultsName('name').setParseAction(compress_whitespace)\n",
    "#     return begin + number + dash + name\n",
    "\n",
    "# def compress_whitespace(s, loc, toks):\n",
    "#     return [re.sub(r'\\s+', ' ', tok).strip() for tok in toks]\n",
    "\n",
    "def parse(data):\n",
    "    # should match anything that looks like a header\n",
    "    header = Regex(re.compile(r'-[A-Z0-9]+-')) # Regex(pattern, flags=0, asGroupList=False, asMatch=False)\n",
    "\n",
    "    # -CITE- (ignore)                         # skipping over all undefined text until the matched expression is found.\n",
    "    citation = SkipTo('-EXPCITE-').suppress() # Suppresses the output of this ParserElement; useful to keep punctuation from cluttering up returned output.\n",
    "    cite_section = section('CITE', citation)  # section(header, other)\n",
    "\n",
    "    # -EXPCITE- (parse)\n",
    "    # grab title number, title name, chapter number, chapter name\n",
    "    title = Group(tc('TITLE', 'CHAPTER')).setResultsName('title')\n",
    "    chapter = Group(tc('CHAPTER', '-HEAD-')).setResultsName('chapter')\n",
    "    expcite_section = section('EXPCITE', title + chapter)\n",
    "\n",
    "    # -HEAD- (parse)\n",
    "    # two possible forms of section number:\n",
    "    # > Sec. 1. <head_text>\n",
    "    # > CHAPTER 1 - <head_text>\n",
    "    sec_number1 = Literal(\"Sec.\").suppress() \\\n",
    "                  + Regex(r'\\d+\\w?.').setResultsName('section').setParseAction(lambda s, loc, toks: toks[0][:-1])\n",
    "    \n",
    "    sec_number2 = Literal(\"CHAPTER\").suppress() + Word(nums).setResultsName('section') + Literal(\"-\")\n",
    "    \n",
    "    sec_number = sec_number1 | sec_number2\n",
    "    head_text = SkipTo(header).setResultsName('head')\\\n",
    "                .setParseAction(compress_whitespace)\n",
    "    \n",
    "    head = sec_number + head_text\n",
    "    head_section = section('HEAD', head)\n",
    "\n",
    "    # -STATUTE- (parse)\n",
    "    statute = SkipTo(header)\\\n",
    "              .setResultsName('statute')\\\n",
    "              .setParseAction(compress_whitespace)\n",
    "    statute_section = section('STATUTE', statute)\n",
    "\n",
    "    # -End- (ignore)\n",
    "    end_section = SkipTo('-End-', include=True)\n",
    "\n",
    "    # do parsing\n",
    "    parser = OneOrMore(Group(cite_section \\\n",
    "                             + expcite_section \\\n",
    "                             + head_section \\\n",
    "                             + Optional(statute_section) \\\n",
    "                             + end_section))\n",
    "    result = parser.parseString(data)\n",
    "\n",
    "    return result\n",
    "\n",
    "def write_to_csv(parsed_data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        for item in parsed_data:\n",
    "            row = [item['title']['number'],\n",
    "                   item['title']['name'],\n",
    "                   item['chapter']['number'],\n",
    "                   item['chapter']['name'],\n",
    "                   item['section'],\n",
    "                   item['head'],\n",
    "                   item['statute']]\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "# your data is assumed to be in <source.txt>\n",
    "with open('source.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "result = parse(data)\n",
    "write_to_csv(result, 'output.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import *\n",
    "# define grammar of a greeting\n",
    "parse_string = \"Hello, World!\"\n",
    "parse_model = Word(alphas) + \",\" + Word(alphas) + \"!\"\n",
    "\n",
    "print(parse_model.parseString(parse_string)) # a nested list, a dictionary, or an object with named attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Literal('blah').parseString('blahword helooblah blah is my name blah'))  # -> ['blah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
